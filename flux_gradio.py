import gradio as gr
import os
from huggingface_hub import InferenceClient

# ç¦ç”¨ä»£ç†è®¾ç½®
os.environ['NO_PROXY'] = '*'
os.environ['no_proxy'] = '*'

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = InferenceClient(
    provider="fal-ai",
    api_key="æ›¿æ¢æˆä½ çš„haggingface token",
)

def generate_image(prompt):
    try:
        # ä½¿ç”¨InferenceClientç”Ÿæˆå›¾åƒ
        image = client.text_to_image(
            prompt,
            model="black-forest-labs/FLUX.1-Krea-dev",
        )
        return image, f"âœ… ç”ŸæˆæˆåŠŸï¼"
    except Exception as e:
        return None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"

# åˆ›å»ºGradioç•Œé¢
iface = gr.Interface(
    fn=generate_image,
    inputs=gr.Textbox(lines=3, placeholder="è¾“å…¥å›¾åƒæè¿°...(ä»…æ”¯æŒè‹±æ–‡)", label="æç¤ºè¯"),
    outputs=[
        gr.Image(type="pil", label="ç”Ÿæˆçš„å›¾åƒ"),
        gr.Textbox(label="çŠ¶æ€", interactive=False)
    ],
    title="ğŸ¨ Fyå›¾åƒç”Ÿæˆå™¨",
    description="è¾“å…¥æ–‡æœ¬æè¿°ï¼Œç”Ÿæˆç›¸åº”çš„å›¾åƒï¼ˆfyå‡ºå“ï¼‰",
    examples=[
        
    ]
)

if __name__ == "__main__":
    iface.launch(share=True) 